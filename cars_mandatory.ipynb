{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Regression Problem:\n",
        "\n",
        "### Forudsigelse af bilens brændstofforbrug (mpg):"
      ],
      "metadata": {
        "id": "Er5acvoU8boS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importer nødvendige biblioteker\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# 1. Indlæs datasættet\n",
        "data = pd.read_csv('cars.csv')\n",
        "\n",
        "# 2. Konverter '?' til NaN og fjern manglende værdier\n",
        "data['horsepower'] = pd.to_numeric(data['horsepower'], errors='coerce')\n",
        "data_cleaned = data.dropna()\n",
        "\n",
        "# 3. Fjern irrelevante kolonner\n",
        "data_cleaned = data_cleaned.drop(columns=['car name'])\n",
        "\n",
        "# 4. Normaliser vægt og acceleration\n",
        "scaler = StandardScaler()\n",
        "data_cleaned[['weight', 'acceleration']] = scaler.fit_transform(data_cleaned[['weight', 'acceleration']])\n"
      ],
      "metadata": {
        "id": "n1ft_0ssTTmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Opret nye features\n",
        "data_cleaned['power_to_weight'] = data_cleaned['horsepower'] / data_cleaned['weight']\n",
        "data_cleaned['displacement_to_cylinder'] = data_cleaned['displacement'] / data_cleaned['cylinders']\n",
        "data_cleaned['efficiency_score'] = (data_cleaned['horsepower'] * data_cleaned['weight']) / data_cleaned['acceleration']\n",
        "\n",
        "# 6. Definér features og target\n",
        "X = data_cleaned[['displacement', 'weight', 'cylinders', 'horsepower', 'acceleration',\n",
        "                  'power_to_weight', 'displacement_to_cylinder', 'efficiency_score']]\n",
        "y = data_cleaned['mpg']"
      ],
      "metadata": {
        "id": "5XIpeTDQ8Diz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOkze1DnOAjw",
        "outputId": "777d5f3e-ddd2-4ddd-f139-144704217b68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Træningssæt: (274, 8) (274,)\n",
            "Test sæt: (59, 8) (59,)\n",
            "Validerings sæt: (59, 8) (59,)\n"
          ]
        }
      ],
      "source": [
        "# 7. Split data i træning (70%), test (15%) og validering (15%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(\"Træningssæt:\", X_train.shape, y_train.shape)\n",
        "print(\"Test sæt:\", X_test.shape, y_test.shape)\n",
        "print(\"Validerings sæt:\", X_val.shape, y_val.shape)\n",
        "\n",
        "\n",
        "# 8. Opret model og kør GridSearchCV for at optimere parametre\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Grid Search til at finde den bedste kombination af hyperparametre\n",
        "grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
        "                           param_grid=param_grid,\n",
        "                           cv=5,\n",
        "                           n_jobs=-1)\n",
        "\n",
        "# Træn modellen\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Hent den bedste model fra GridSearchCV\n",
        "best_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Forudsig resultater på testdata\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluering på testdata\n",
        "mae_test = mean_absolute_error(y_test, y_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2_test = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nTest-sættets præstation:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_test:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_test:.2f}\")\n",
        "print(f\"R² Score: {r2_test:.2f}\")\n",
        "\n",
        "# Forudsig resultater på valideringsdata\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "\n",
        "# Evaluering på valideringsdata\n",
        "mae_val = mean_absolute_error(y_val, y_val_pred)\n",
        "rmse_val = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
        "r2_val = r2_score(y_val, y_val_pred)\n",
        "\n",
        "print(\"\\nValideringssættets præstation:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_val:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_val:.2f}\")\n",
        "print(f\"R² Score: {r2_val:.2f}\")\n",
        "\n",
        "\n",
        "# 10. Evaluer modellen\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nModellens præstation:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(f\"R² Score: {r2:.2f}\")"
      ],
      "metadata": {
        "id": "Xm8mFog_zoEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Visualiser resultater\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "plt.xlabel(\"Faktisk MPG\")\n",
        "plt.ylabel(\"Forudsagt MPG\")\n",
        "plt.title(\"Forudsigelse af MPG baseret på bilens egenskaber\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6Uvf8TBezsT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Residual plot (for at vurdere systematiske fejl)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.residplot(x=y_test, y=y_pred, lowess=True, line_kws={'color': 'red'})\n",
        "plt.title(\"Residual plot\")\n",
        "plt.xlabel(\"Faktisk MPG\")\n",
        "plt.ylabel(\"Residualer\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wFeIstO70pI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Feature Importance plot\n",
        "importances = best_model.feature_importances_\n",
        "feature_names = X.columns\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=importances, y=feature_names)\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MyBQi5C-0tD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression Problem:\n",
        "### Forudsigelse af bilens oprindelse baseret på dens tekniske egenskaber"
      ],
      "metadata": {
        "id": "J-69sc2b8q3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Definer X (features) og y (target)\n",
        "X = data_cleaned.drop(columns=['origin'])  # Features\n",
        "y = data_cleaned['origin']  # Target (1 = USA, 2 = Europa, 3 = Asien)\n",
        "\n",
        "# 2. Skaler alle features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 3. Split data i træning (70%), test (15%) og validering (15%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.30, random_state=42)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)\n",
        "\n",
        "# 4. GridSearchCV til optimering\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(LogisticRegression(multi_class='ovr', random_state=42),\n",
        "                           param_grid, cv=5, n_jobs=-1)\n",
        "\n",
        "\n",
        "# 5. Træn GridSearchCV\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "EdhVZN4s8kli",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Evaluering\n",
        "# Bedste model\n",
        "best_model = grid_search.best_estimator_\n",
        "print(f\"Bedste parametre: {grid_search.best_params_}\")\n",
        "\n",
        "# Evaluer på træningssæt\n",
        "train_accuracy = accuracy_score(y_train, best_model.predict(X_train))\n",
        "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
        "\n",
        "# Evaluer på valideringssæt\n",
        "val_accuracy = accuracy_score(y_val, best_model.predict(X_val))\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "\n",
        "# Evaluer på testsæt\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "qXDjJuVJ9UAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "print(\"\\nConfusion Matrix on the Test Set:\")\n",
        "print(cm)\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=['USA', 'Europe', 'Asia'],\n",
        "            yticklabels=['USA', 'Europe', 'Asia'])\n",
        "plt.title('Confusion Matrix for Car Origin (Test Set)')\n",
        "plt.xlabel('Predicted Origin')\n",
        "plt.ylabel('Actual Origin')\n",
        "plt.show()\n",
        "\n",
        "# 8. Classification Report\n",
        "print(\"\\nClassification Report on the Test Set:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['USA', 'Europe', 'Asia']))"
      ],
      "metadata": {
        "id": "9SAqCyzL_x6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YY_-TYfvEnRz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}